# -*- coding: utf-8 -*-
"""assign2q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16WsDrltPU_hX-kDnyYAbJoFloTkXP1oc
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
from numpy import genfromtxt
import math
import pandas as pd
from collections import Counter
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import random
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.decomposition import PCA
from sklearn.svm import LinearSVC
from sklearn import linear_model

"""### Opening the dataset files and storing in a dictionary."""

def unpickle(file):
    import pickle
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict

dict1 = unpickle('/content/drive/My Drive/Assignment-2_Dataset//Datasets/Question-1/cifar-10-python/cifar-10-batches-py/data_batch_1')
dict2 = unpickle('/content/drive/My Drive/Assignment-2_Dataset//Datasets/Question-1/cifar-10-python/cifar-10-batches-py/data_batch_2')
dict3 = unpickle('/content/drive/My Drive/Assignment-2_Dataset//Datasets/Question-1/cifar-10-python/cifar-10-batches-py/data_batch_3')
dict4 = unpickle('/content/drive/My Drive/Assignment-2_Dataset//Datasets/Question-1/cifar-10-python/cifar-10-batches-py/data_batch_4')
dict5 = unpickle('/content/drive/My Drive/Assignment-2_Dataset//Datasets/Question-1/cifar-10-python/cifar-10-batches-py/data_batch_5')
print(dict1)
print(dict1.keys())
X = np.concatenate((dict1[b'data'], dict2[b'data'], dict3[b'data'], dict4[b'data'], dict5[b'data']), axis=0)
y = np.concatenate((dict1[b'labels'], dict2[b'labels'], dict3[b'labels'], dict4[b'labels'], dict5[b'labels']), axis=0)
print(X.shape)
print(y.shape)

"""### Applying Principal Component Analysis (PCA) on the data to reduce it to 150 components."""

pca = PCA(n_components=150)
X = pca.fit_transform(X)
print(X.shape)

"""### Splitting the training data into train and test sets."""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)

"""## Testing Linear SVC accuracy with different values of C

### Linear SVC with C=1
"""

clf_c1 = LinearSVC(C=1.0, max_iter=10000)
clf_c1.fit(X_train, y_train)

#LinearSVC with n_components=300
y_pred_c1 = clf_c1.predict(X_test)
accuracy_c1 = accuracy_score(y_test, y_pred_c1)
print("Accuracy: ",accuracy_c1*100)

f1 = f1_score(y_test, y_pred_c1,  average='macro')
print("F1 score: ",f1)

print(confusion_matrix(y_test, y_pred_c1))

"""### Linear SVC with C=2"""

clf_c2 = LinearSVC(C=2.0)
clf_c2.fit(X_train, y_train)

y_pred_c2 = clf_c2.predict(X_test)
accuracy_c2 = accuracy_score(y_test, y_pred_c2)
print("Accuracy: ",accuracy_c2*100)

f1 = f1_score(y_test, y_pred_c2,  average='macro')
print("F1 score: ",f1)

print(confusion_matrix(y_test, y_pred_c2))

"""### Linear SVC with C=4"""

clf_c4 = LinearSVC(C=4.0)
clf_c4.fit(X_train, y_train)

y_pred_c4 = clf_c4.predict(X_test)
accuracy_c4 = accuracy_score(y_test, y_pred_c4)
print("Accuracy: ",accuracy_c4*100)

f1 = f1_score(y_test, y_pred_c4,  average='macro')
print("F1 score: ",f1)

print(confusion_matrix(y_test, y_pred_c4))

pca = PCA(n_components=200)
X = pca.fit_transform(X)
print(X.shape)

#LinearSVC with n_components=200
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: ",accuracy*100)

pca = PCA(n_components=100)
X = pca.fit_transform(X)
print(X.shape)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)

clf_pca_55 = LinearSVC()
clf_pca_55.fit(X_train, y_train)

#LinearSVC with n_components=200
y_pred_pca_55 = clf_pca_55.predict(X_test)
accuracy_pca_55 = accuracy_score(y_test, y_pred_pca_55)
print("Accuracy: ",accuracy_pca_55*100)

"""## Testing the accuracy, F1 score and confusion matrix for SGD Classifier"""

#SGD
clf_sgd = linear_model.SGDClassifier(alpha=1000,n_jobs=-1,max_iter=100000)
clf_sgd.fit(X_train, y_train)

#SGD
y_pred_sgd=clf_sgd.predict(X_test)
accuracy_sgd = accuracy_score(y_test, y_pred_sgd)
print("Accuracy: ",accuracy_sgd*100)

f1 = f1_score(y_test, y_pred_sgd,  average='macro')
print("F1 score: ",f1)

print(confusion_matrix(y_test,y_pred_sgd))

"""## We see the accuracy obtained is 37.19 %"""