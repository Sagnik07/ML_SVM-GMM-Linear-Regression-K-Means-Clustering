{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tDTLMyoqae51"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import DataFrame\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import sklearn\n",
    "import os\n",
    "import matplotlib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.metrics.cluster import homogeneity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQ_ycpQr7ASE"
   },
   "source": [
    "## Training data\n",
    "In this section, we are reading the contents from the data files and storing them in a dictionary where the keys are the paths of the files and values it's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/content/drive/My Drive/Assignment-2_Dataset/Datasets/Question-6/dataset'\n",
    "file_name = \"\"\n",
    "files = {}\n",
    "for a,b,f in os.walk(path):\n",
    "  for file in f:\n",
    "    if \".txt\" in file:\n",
    "      file_name = os.path.join(a,file)\n",
    "      f1 = open(file_name, 'rb')\n",
    "      file_data = f1.read().decode(errors=\"replace\")\n",
    "      file_data = \" \".join(file_data.split())\n",
    "      files[file_name] = file_data\n",
    "\n",
    "# files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PSPu038z_NE1"
   },
   "source": [
    "### We convert the data to numpy array by vectorizing it using TfidVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "vectors = vectorizer.fit_transform(files.values())\n",
    "# X=vectors\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "# print(feature_names)\n",
    "# print(vectors.shape)\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "# df\n",
    "X=df.to_numpy()\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bM5AhTOk_XXS"
   },
   "source": [
    "### Here we are defining the number of clusters. In this case we take it as 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mM8i2_mi_UWa"
   },
   "outputs": [],
   "source": [
    "no_of_clusters=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QdlTlxOe_1ir"
   },
   "source": [
    "### We are assigning random centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids=np.random.uniform(size=(no_of_clusters,X.shape[1]))\n",
    "for i in range(no_of_clusters):\n",
    "  centroids[i] = centroids[i]/(np.linalg.norm(centroids[i]))\n",
    "\n",
    "# print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAxXE34Kji5-"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(x):\n",
    "  return (np.sqrt(np.sum(x**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZv2NA4QhQ8U"
   },
   "source": [
    "# K-Means Algorithm\n",
    "We formalize the K-Means algorithm in the following section. We take out the distance of every data point from the centroids and assign them to a cluster which belongs to the centroid that is closest to that point. We return the indices of the data points that belong to each cluster as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "loop=0\n",
    "prev_centroids=centroids\n",
    "for loop in range(15):\n",
    "  # print(loop)\n",
    "  classes={}\n",
    "  indexes={}\n",
    "  begin=0\n",
    "\n",
    "  for i in range(no_of_clusters):\n",
    "    indexes[i] = []\n",
    "    classes[i] = []\n",
    "\n",
    "  for row in X:\n",
    "    # for c in range(len(centers)):\n",
    "    #   dists[c]=np.linalg.norm(row-centers[c])\n",
    "    distances = [euclidean_distance(row-centroids[i]) for i in range(len(centroids))]\n",
    "    # print(dists)\n",
    "    minimum_distance = min(distances)\n",
    "    m_index = distances.index(minimum_distance)\n",
    "    # print(index)\n",
    "    indexes[m_index].append(begin)\n",
    "    classes[m_index].append(row)\n",
    "    begin = begin + 1\n",
    "\n",
    "  for i in range(len(centroids)):\n",
    "    centroids[i] = np.mean(classes[i], axis = 0)\n",
    "  \n",
    "# print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nj7y3sxWh1gf"
   },
   "source": [
    "### In the following two sections, we store the original labels of the files in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "file_labels={}\n",
    "for k in files.keys():\n",
    "  x=k.split(\"_\")\n",
    "  # print(x)\n",
    "  file_labels[i]=int(x[2][0])\n",
    "  i=i+1\n",
    "\n",
    "# print(file_no)\n",
    "# print(file_labels)\n",
    "# print(len(file_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBk2znTDMQbp"
   },
   "outputs": [],
   "source": [
    "orig_labels={}\n",
    "for i in indexes.keys():\n",
    "  for j in indexes[i]:\n",
    "    # print(j)\n",
    "    orig_labels[j]=file_labels[j]\n",
    "\n",
    "orig_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LkiGS0IhiAXr"
   },
   "source": [
    "### To predict our output, we use majority voting of the cluster points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hRVkD2UaqESt"
   },
   "outputs": [],
   "source": [
    "def find_majority_label(label):\n",
    "    return max(set(label), key = label.count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label_of_cluster={}\n",
    "for loop in range(5):\n",
    "  li=[]\n",
    "  for i in indexes[loop]:\n",
    "    li.append(file_labels[i])\n",
    "#   print(find_majority_label(li))\n",
    "  pred_label_of_cluster[loop]=find_majority_label(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsBMqXhN82g5"
   },
   "outputs": [],
   "source": [
    "pred_label={}\n",
    "for i in indexes.keys():\n",
    "  for j in indexes[i]:\n",
    "    # print(j)\n",
    "    pred_label[j]=pred_label_of_cluster[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CF6ZNcg2iVQT"
   },
   "source": [
    "## Result\n",
    "We measure the accuracy of our model by comparing our predicted labels with the original labels of the files.\n",
    "\n",
    "The accuracy score obtained is **84.34%**\n",
    "\n",
    "Note: This value of accuracy score may vary for every execution as initially the centroids are assigned randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xZNFbH2z-w8l",
    "outputId": "be799d67-7ced-4876-9c80-2147ef4ddc91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8434782608695652"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true=orig_labels.values()\n",
    "y_pred=pred_label.values()\n",
    "y_true=list(y_true)\n",
    "y_pred=list(y_pred)\n",
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tjNi-qM4VLt"
   },
   "source": [
    "### The homogeneity score is calculated and found out to be **0.69**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vMXp6xZjrQDh",
    "outputId": "09c749c2-30c7-4a5a-b553-a9f63aedf9fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6989383929356456"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homogeneity_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of assign2q6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
